{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLwwrZvFBykZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "outputId": "e5c4a534-2375-451a-c3a3-7bbb4e6f59d7"
      },
      "source": [
        "!pip install progressbar\n",
        "!pip install transliteration"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting progressbar\n",
            "  Downloading https://files.pythonhosted.org/packages/a3/a6/b8e451f6cff1c99b4747a2f7235aa904d2d49e8e1464e0b798272aa84358/progressbar-2.5.tar.gz\n",
            "Building wheels for collected packages: progressbar\n",
            "  Building wheel for progressbar (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for progressbar: filename=progressbar-2.5-cp36-none-any.whl size=12074 sha256=46c726f0c02583cba2574241359c94157e48022a5e33db6f86c66714abc37aa1\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/e9/6b/ea01090205e285175842339aa3b491adeb4015206cda272ff0\n",
            "Successfully built progressbar\n",
            "Installing collected packages: progressbar\n",
            "Successfully installed progressbar-2.5\n",
            "Collecting transliteration\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/56/3f76652f21634a4753e8880f0d37834805476ec7b83c36e6a2383ca2288d/transliteration-0.4.1.tar.gz (846kB)\n",
            "\u001b[K     |████████████████████████████████| 849kB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from transliteration) (46.3.0)\n",
            "Collecting normalizer\n",
            "  Downloading https://files.pythonhosted.org/packages/67/ab/a1a09513d1f157ca17dca1cd9ee2c56fa40a8945c466398c37a0daae10d1/normalizer-0.2.1.tar.gz\n",
            "Collecting silpa_common\n",
            "  Downloading https://files.pythonhosted.org/packages/8d/55/452f5103cb7071d188a818d9e2f12c19c4c8a12124a28aaa212eb6716a4d/silpa_common-0.3.tar.gz\n",
            "Building wheels for collected packages: transliteration, normalizer, silpa-common\n",
            "  Building wheel for transliteration (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transliteration: filename=transliteration-0.4.1-cp36-none-any.whl size=848954 sha256=1e67847c13ed6bae6a494fb37c61939f49e13b2a4fa5adec88190e6bd0caed96\n",
            "  Stored in directory: /root/.cache/pip/wheels/79/9c/2d/52407b904883634c54376392b566005cca6b00763d6d3280f8\n",
            "  Building wheel for normalizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for normalizer: filename=normalizer-0.2.1-cp36-none-any.whl size=3755 sha256=65db7083576c8957272d27a43a40a0f566d0b33035ac87983aa81ab4f29072ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/bd/7d/f4333e45927815ebaae3241a46343349c0cccbc0e413b87fe5\n",
            "  Building wheel for silpa-common (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for silpa-common: filename=silpa_common-0.3-cp36-none-any.whl size=8453 sha256=25c52b6baa9ef549f063cee6269d9491e95c2e5d445cc763fbbc95f34ca6d35c\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/4f/ba/604a82bf904740f1a1d3ad88029c0df5c638bd8825a3cb972d\n",
            "Successfully built transliteration normalizer silpa-common\n",
            "Installing collected packages: normalizer, silpa-common, transliteration\n",
            "Successfully installed normalizer-0.2.1 silpa-common-0.3 transliteration-0.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmE9V_7MHUVt",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSZMzBngBzy7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "outputId": "ea4091f1-0556-4308-abcd-dc27f913f01e"
      },
      "source": [
        "!pip install indic_transliteration"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting indic_transliteration\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/73/0491e03996146fc605f2cacf751968f35cfc586aadd9e5181fa47b0f9bdf/indic_transliteration-1.9.4-py3-none-any.whl (94kB)\n",
            "\r\u001b[K     |███▌                            | 10kB 17.1MB/s eta 0:00:01\r\u001b[K     |███████                         | 20kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 30kB 5.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 40kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 51kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 61kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 71kB 5.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 81kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 92kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 4.5MB/s \n",
            "\u001b[?25hCollecting backports.functools-lru-cache\n",
            "  Downloading https://files.pythonhosted.org/packages/da/d1/080d2bb13773803648281a49e3918f65b31b7beebf009887a529357fd44a/backports.functools_lru_cache-1.6.1-py2.py3-none-any.whl\n",
            "Collecting splinter\n",
            "  Downloading https://files.pythonhosted.org/packages/d1/46/bb01079ef246d61c2432420c6cd63ecb11e0e909a5da42abcb407e0fb4e2/splinter-0.13.0.tar.gz\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from indic_transliteration) (2019.12.20)\n",
            "Collecting selenium>=3.141.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/d6/4294f0b4bce4de0abf13e17190289f9d0613b0a44e5dd6a7f5ca98459853/selenium-3.141.0-py2.py3-none-any.whl (904kB)\n",
            "\u001b[K     |████████████████████████████████| 911kB 10.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from splinter->indic_transliteration) (1.12.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from selenium>=3.141.0->splinter->indic_transliteration) (1.24.3)\n",
            "Building wheels for collected packages: splinter\n",
            "  Building wheel for splinter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for splinter: filename=splinter-0.13.0-cp36-none-any.whl size=33304 sha256=19e97197dadb19fd40ba181c70c0af9dbd4c9098f8fcf549dad0d69dc0f363a4\n",
            "  Stored in directory: /root/.cache/pip/wheels/fd/ff/26/2fc56897bcbe58908bbb2002c53affb516e5e6daa425aefdef\n",
            "Successfully built splinter\n",
            "Installing collected packages: backports.functools-lru-cache, selenium, splinter, indic-transliteration\n",
            "Successfully installed backports.functools-lru-cache-1.6.1 indic-transliteration-1.9.4 selenium-3.141.0 splinter-0.13.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOtQRgJNCDDO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "0c8f6e01-f33d-4c67-d19c-7dce5ca2f30e"
      },
      "source": [
        "import urllib.request\n",
        "import os\n",
        "import zipfile\n",
        "import glob\n",
        "import numpy as np\n",
        "import random\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import callbacks\n",
        "from keras.utils import plot_model\n",
        "import matplotlib.pyplot as plt\n",
        "import progressbar\n",
        "from indic_transliteration import sanscript"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZUN0kG6CIr4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus_path = \"corpus\"\n",
        " \n",
        "# Hyperparameters.\n",
        "transliteration = True \n",
        "input_length = 40\n",
        "output_length = 1 \n",
        "data_set_size = 100000\n",
        "num_epochs = 50 \n",
        "batch_size = 256 \n",
        "hidden_size = 350 \n",
        "generation_length = 100 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jmxn31NCMoa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "    # download corpus.\n",
        "    ensure_corpus()\n",
        " \n",
        "    (train_input, train_output) = load_data()\n",
        "    print(\"train_input\", train_input.shape, \" \", train_output.shape)\n",
        " \n",
        "    global model\n",
        "    model = create_model()\n",
        "\n",
        "    generate_callback = callbacks.LambdaCallback(on_epoch_end=on_epoch_end)\n",
        " \n",
        "    history = model.fit(\n",
        "        train_input, train_output,\n",
        "        epochs=num_epochs, batch_size=batch_size,\n",
        "        callbacks = [generate_callback]\n",
        "    )\n",
        " \n",
        "  \n",
        "    model.save(\"model.h5\")\n",
        " \n",
        "   \n",
        "    plot_history(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvl_X5cnCRKr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ensure_corpus():\n",
        "\n",
        "    \n",
        "    if os.path.exists(\"corpus\") == False:\n",
        "        # Download the whole git-repository as a zip.\n",
        "        print(\"Downloading corpus...\")\n",
        "        corpus_url = \"https://github.com/cltk/hindi_text_ltrc/archive/master.zip\"\n",
        "        corpus_zip_path = \"master.zip\"\n",
        "        urllib.request.urlretrieve(corpus_url, corpus_zip_path)\n",
        " \n",
        "       \n",
        "        \n",
        "        zip_file = zipfile.ZipFile(corpus_zip_path, 'r')\n",
        "        zip_file.extractall(corpus_path)\n",
        "        zip_file.close()\n",
        " \n",
        "      \n",
        "        os.remove(corpus_zip_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r60fBjilCUyA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data():\n",
        "\n",
        "    glob_path = os.path.join(corpus_path, \"**/*.txt\")\n",
        "    paths = glob.glob(glob_path, recursive=True)\n",
        "\n",
        "    print(\"Loading all files...\")\n",
        "    file_contents = []\n",
        "    for path in paths:\n",
        "        file_content = open(path, \"r\", encoding = \"utf-8\").read()\n",
        "        if transliteration == True:\n",
        "            file_content = sanscript.transliterate(file_content, sanscript.DEVANAGARI, sanscript.IAST)\n",
        "        file_content = clean_text(file_content)\n",
        "        file_contents.append(file_content)\n",
        " \n",
        "    print(\"Getting character set...\")\n",
        "    global full_text\n",
        "    full_text = \" \".join(file_contents)\n",
        "    global character_set\n",
        "    character_set = get_character_set(full_text)\n",
        "    print(\"Character set:\", character_set)\n",
        " \n",
        "    # Process the data.\n",
        "    data_input = []\n",
        "    data_output = []\n",
        "    current_size = 0\n",
        "    print(\"Generating data set...\")\n",
        "    bar = progressbar.ProgressBar(maxval = data_set_size)\n",
        "    bar.start()\n",
        "    while current_size < data_set_size:\n",
        "        random_file_content = random.choice(file_contents)\n",
        "        # print(\"random : \", random_file_content)\n",
        "        random_string = random_substring_of_length(random_file_content, input_length + output_length)\n",
        " \n",
        "        random_string_encoded = encode_string(random_string)\n",
        " \n",
        "        input_sequence = random_string_encoded[:input_length]\n",
        "        output_sequence = random_string_encoded[input_length:]\n",
        " \n",
        "        data_input.append(input_sequence)\n",
        "        data_output.append(output_sequence)\n",
        " \n",
        "        current_size += 1\n",
        "        bar.update(current_size)\n",
        "    bar.finish()\n",
        "\n",
        "    train_input = np.array(data_input)\n",
        "    train_output = np.array(data_output)\n",
        "    return (train_input, train_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gnl1SEzZCZ73",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text(text):\n",
        "    \n",
        "    text = text.replace(\"\\t\", \" \")\n",
        "    text = text.replace(\"\\n\", \" \")\n",
        "    text = text.replace(\"।\", \" \")\n",
        "    text = text.replace(\"0\", \" \")\n",
        "    text = text.replace(\"1\", \" \")\n",
        "    text = text.replace(\"2\", \" \")\n",
        "    text = text.replace(\"3\", \" \")\n",
        "    text = text.replace(\"4\", \" \")\n",
        "    text = text.replace(\"5\", \" \")\n",
        "    text = text.replace(\"6\", \" \")\n",
        "    text = text.replace(\"7\", \" \")\n",
        "    text = text.replace(\"8\", \" \")\n",
        "    text = text.replace(\"9\", \" \")\n",
        "    text = \" \".join(text.split())\n",
        "    \n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZKpiPMsChS0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_character_set(string):\n",
        "    # get all unique characters.\n",
        "    return sorted(list(set(string)))\n",
        "\n",
        "def random_substring_of_length(string, length):\n",
        "    # get random substring.\n",
        "    start_index = random.randint(0, len(string) - length)\n",
        "    return string[start_index:start_index + length]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILOhEmSVCj2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode_string(string):\n",
        "    \"\"\" Encodes a string in order to use it in the Neural Network context. \"\"\"\n",
        "    # character_set = [' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', '/', ':', '=', '?', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'y', 'z', '|', 'Ê', 'Ù', 'Ý', 'è', 'é', 'ê', 'í', 'ñ', 'û', 'ā', 'ġ', 'ī', 'ś', 'ū', '̐', '़', 'ॅ', 'ॉ', 'ḍ', 'ḥ', 'ḷ', 'ḻ', 'ṃ', 'ṅ', 'ṇ', 'ṛ', 'ṝ', 'ṣ', 'ṭ', '\\u200c', '\\u200d', '–', '’']\n",
        "    encoded_string = []\n",
        "    for character in string:\n",
        "        encoded_character = np.zeros((len(character_set),))\n",
        "        one_hot_index = character_set.index(character)\n",
        "        encoded_character[one_hot_index] = 1.0\n",
        "        encoded_string.append(encoded_character)\n",
        "    return np.array(encoded_string)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cT5VALBjCmJd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model():\n",
        "\n",
        "    input_shape = (input_length, len(character_set))\n",
        " \n",
        "    model = models.Sequential()\n",
        "    model.add(layers.LSTM(hidden_size, input_shape=input_shape, activation=\"relu\"))\n",
        "    model.add(layers.Dense(output_length * len(character_set), activation=\"relu\"))\n",
        "    model.add(layers.Reshape((output_length, len(character_set))))\n",
        "    model.add(layers.TimeDistributed(layers.Dense(len(character_set), activation=\"softmax\")))\n",
        "    model.summary()\n",
        " \n",
        "    model.compile(\n",
        "        loss='categorical_crossentropy',\n",
        "        optimizer='adam',\n",
        "        metrics=['accuracy'])\n",
        " \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeloodZ6Cobs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_history(history):\n",
        "\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.savefig(\"accuracy.png\")\n",
        "    plt.clf()\n",
        "\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.savefig(\"loss.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwCfy66rCrkT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def on_epoch_end(epoch, logs):\n",
        "\n",
        "    if epoch % 10 == 0 and epoch != 0:\n",
        "        print(\"\")\n",
        " \n",
        "        for temperature in [0.0, 0.25, 0.5, 0.75, 1.0]:\n",
        "            # print(\"Temperature:\", temperature)\n",
        "            global full_text\n",
        "            random_string = random_substring_of_length(full_text, input_length)\n",
        "            result_string = random_string\n",
        "            print(\"Seed string:  \", sanscript.transliterate(random_string, sanscript.IAST, sanscript.DEVANAGARI))\n",
        "            input_sequence = encode_string(random_string)\n",
        " \n",
        "            \n",
        "            while len(result_string) < generation_length:\n",
        "                output_sequence = model.predict(np.expand_dims(input_sequence, axis=0))\n",
        "                output_sequence = output_sequence[0]\n",
        "                decoded_string = decode_sequence(output_sequence, temperature)\n",
        "                output_sequence = encode_string(decoded_string)\n",
        "                result_string += decoded_string\n",
        "                input_sequence = input_sequence[output_length:]\n",
        "                input_sequence = np.concatenate((input_sequence, output_sequence), axis=0)\n",
        " \n",
        "            print(\"Result string:\", sanscript.transliterate(result_string, sanscript.IAST, sanscript.DEVANAGARI), len(result_string))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq6SFeYxCvkx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generate_callback = callbacks.LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qg4tB7plCzPf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(sequence, temperature=0.0):\n",
        "\n",
        "    result_string = \"\"\n",
        "    for element in sequence:\n",
        "        index = get_index_from_prediction(element)\n",
        "        character = character_set[index]\n",
        "        result_string += character\n",
        "    return result_string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xq5q_NDtC1FV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_index_from_prediction(prediction, temperature=0.0):\n",
        "\n",
        "   \n",
        "    if temperature == 0.0:\n",
        "        return np.argmax(prediction)\n",
        " \n",
        "   \n",
        "    else:\n",
        "        prediction = np.asarray(prediction).astype('float64')\n",
        "        prediction = np.log(prediction) / temperature\n",
        "        exp_prediction= np.exp(prediction)\n",
        "        prediction = exp_prediction / np.sum(exp_prediction)\n",
        "        probabilities = np.random.multinomial(1, prediction, 1)\n",
        "        return np.argmax(probabilities)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrGoOr03C3ni",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9e66013b-122c-467f-e562-eba4bc23b7a0"
      },
      "source": [
        "main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading corpus...\n",
            "Loading all files...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Getting character set...\n",
            "Character set: [' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', '/', ':', '=', '?', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'y', 'z', '|', 'Ê', 'Ù', 'Ý', 'è', 'é', 'ê', 'í', 'ñ', 'û', 'ā', 'ġ', 'ī', 'ś', 'ū', '̐', '़', 'ॅ', 'ॉ', 'फ़', 'ḍ', 'ḥ', 'ḷ', 'ḻ', 'ṃ', 'ṅ', 'ṇ', 'ṛ', 'ṝ', 'ṣ', 'ṭ', '\\u200c', '\\u200d', '–', '’']\n",
            "Generating data set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train_input (100000, 40, 73)   (100000, 1, 73)\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 350)               593600    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 73)                25623     \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 1, 73)             0         \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 1, 73)             5402      \n",
            "=================================================================\n",
            "Total params: 624,625\n",
            "Trainable params: 624,625\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "100000/100000 [==============================] - 59s 592us/step - loss: 3.1145 - accuracy: 0.2416\n",
            "Epoch 2/50\n",
            "100000/100000 [==============================] - 58s 577us/step - loss: 2.3099 - accuracy: 0.3634\n",
            "Epoch 3/50\n",
            "100000/100000 [==============================] - 58s 582us/step - loss: 2.2141 - accuracy: 0.3797\n",
            "Epoch 4/50\n",
            "100000/100000 [==============================] - 58s 579us/step - loss: 2.1497 - accuracy: 0.3909\n",
            "Epoch 5/50\n",
            "100000/100000 [==============================] - 58s 580us/step - loss: 2.0950 - accuracy: 0.4012\n",
            "Epoch 6/50\n",
            "100000/100000 [==============================] - 58s 580us/step - loss: 2.0411 - accuracy: 0.4136\n",
            "Epoch 7/50\n",
            "100000/100000 [==============================] - 58s 579us/step - loss: 1.9909 - accuracy: 0.4241\n",
            "Epoch 8/50\n",
            "100000/100000 [==============================] - 58s 576us/step - loss: 1.9461 - accuracy: 0.4330\n",
            "Epoch 9/50\n",
            "100000/100000 [==============================] - 58s 581us/step - loss: 1.9087 - accuracy: 0.4437\n",
            "Epoch 10/50\n",
            "100000/100000 [==============================] - 59s 588us/step - loss: 1.8738 - accuracy: 0.4511\n",
            "Epoch 11/50\n",
            "100000/100000 [==============================] - 59s 586us/step - loss: 1.8362 - accuracy: 0.4617\n",
            "\n",
            "Seed string:   ना सबको अच्छा लगता है । पर घर \n",
            "Result string: ना सबको अच्छा लगता है । पर घर करने करता हैं ऽ पर करन करने करता हैं ऽ समत 100\n",
            "Seed string:   टि किसी युवती पर पड जाती तो तुरन्त\n",
            "Result string: टि किसी युवती पर पड जाती तो तुरन्त करन करता हैं ऽ पर करता है ऽ समत करन करने 100\n",
            "Seed string:    यह कुचालि कछु जान न कोई॥ दो -प्र\n",
            "Result string:  यह कुचालि कछु जान न कोई॥ दो -प्रभु सब सब सब करन करन करत करत करत करता 100\n",
            "Seed string:   इव सुरक्षित रखेगा ऽ शर्वनाग र् अच्छ्\n",
            "Result string: इव सुरक्षित रखेगा ऽ शर्वनाग र् अच्छ करने करता हैं ऽ समत करन करने करता हैं ऽ प 100\n",
            "Seed string:   अ जलधर अभिलाषे॥ निदरहिं सरित \n",
            "Result string: अ जलधर अभिलाषे॥ निदरहिं सरित सब करना॥ भर भरत सब सब सब सभाई। भरत स् 100\n",
            "Epoch 12/50\n",
            "100000/100000 [==============================] - 58s 578us/step - loss: 1.8029 - accuracy: 0.4689\n",
            "Epoch 13/50\n",
            "100000/100000 [==============================] - 58s 585us/step - loss: 1.7694 - accuracy: 0.4775\n",
            "Epoch 14/50\n",
            "100000/100000 [==============================] - 58s 583us/step - loss: 1.7364 - accuracy: 0.4862\n",
            "Epoch 15/50\n",
            "100000/100000 [==============================] - 58s 584us/step - loss: 1.7024 - accuracy: 0.4939\n",
            "Epoch 16/50\n",
            "100000/100000 [==============================] - 58s 582us/step - loss: 1.6688 - accuracy: 0.5029\n",
            "Epoch 17/50\n",
            "100000/100000 [==============================] - 58s 582us/step - loss: 1.6351 - accuracy: 0.5117\n",
            "Epoch 18/50\n",
            "100000/100000 [==============================] - 58s 581us/step - loss: 1.5989 - accuracy: 0.5217\n",
            "Epoch 19/50\n",
            "100000/100000 [==============================] - 59s 587us/step - loss: 1.5631 - accuracy: 0.5312\n",
            "Epoch 20/50\n",
            "100000/100000 [==============================] - 58s 580us/step - loss: 1.5258 - accuracy: 0.5414\n",
            "Epoch 21/50\n",
            "100000/100000 [==============================] - 58s 577us/step - loss: 1.4911 - accuracy: 0.5502\n",
            "\n",
            "Seed string:   हुई और कहीं कहीं पर पूर्ण रूप से \n",
            "Result string: हुई और कहीं कहीं पर पूर्ण रूप से कह करते हैं ऽ इस सखास कहारे करते हैं ऐसे और  100\n",
            "Seed string:    । लेकिन गंगाजली को मैके आने के थोड्\n",
            "Result string:  । लेकिन गंगाजली को मैके आने के थोड उ भरदार् कÝन करते हैं ऽ पर भी हैं कहा कै कहा 100\n",
            "Seed string:   हागी। जाइअ अवध देव हित लागी॥ बार \n",
            "Result string: हागी। जाइअ अवध देव हित लागी॥ बार बरन बहु बिभाई। भरत बन भरत बहु की॥ अति समय् 100\n",
            "Seed string:   करने के लिए बाध्य हैं ऽ सबसे बडी \n",
            "Result string: करने के लिए बाध्य हैं ऽ सबसे बडी है ऽ इन करते हैं ऐसी कहा कैसे हैं ऽ इस सब्धा का स् 100\n",
            "Seed string:   आकर प्रपंचबुद्धि गिर पडता है । च्\n",
            "Result string: आकर प्रपंचबुद्धि गिर पडता है । चहै रह सकते हैं ऽ परणर् संसार करने के लिए पर प् 100\n",
            "Epoch 22/50\n",
            "100000/100000 [==============================] - 57s 570us/step - loss: 1.4487 - accuracy: 0.5628\n",
            "Epoch 23/50\n",
            "100000/100000 [==============================] - 57s 572us/step - loss: 1.4095 - accuracy: 0.5735\n",
            "Epoch 24/50\n",
            "100000/100000 [==============================] - 57s 574us/step - loss: 1.4007 - accuracy: 0.5781\n",
            "Epoch 25/50\n",
            "100000/100000 [==============================] - 57s 571us/step - loss: 1.3781 - accuracy: 0.5813\n",
            "Epoch 26/50\n",
            "100000/100000 [==============================] - 57s 571us/step - loss: 1.3044 - accuracy: 0.6032\n",
            "Epoch 27/50\n",
            "100000/100000 [==============================] - 57s 571us/step - loss: 1.2591 - accuracy: 0.6166\n",
            "Epoch 28/50\n",
            "100000/100000 [==============================] - 57s 570us/step - loss: 1.2169 - accuracy: 0.6298\n",
            "Epoch 29/50\n",
            "100000/100000 [==============================] - 56s 565us/step - loss: 1.1783 - accuracy: 0.6406\n",
            "Epoch 30/50\n",
            "100000/100000 [==============================] - 57s 571us/step - loss: 1.1430 - accuracy: 0.6489\n",
            "Epoch 31/50\n",
            "100000/100000 [==============================] - 56s 557us/step - loss: 1.1033 - accuracy: 0.6623\n",
            "\n",
            "Seed string:   ऊ॥ होत चकित चित कोट बिलोकी। सकल\n",
            "Result string: ऊ॥ होत चकित चित कोट बिलोकी। सकल महीम मन मनु मोरी। हैं भरत अनुज झु भय नाहीं॥ 100\n",
            "Seed string:   बतावें ऽ व्य इ चेतना इसीलिए परतंत्र\n",
            "Result string: बतावें ऽ व्य इ चेतना इसीलिए परतंत्र में पूर्ण हमारी प्रेमना का प्रभाव में ऽ करि नरी कैसे  100\n",
            "Seed string:   अजादा है ऽ उससे रूप हाट की नयी र् न\n",
            "Result string: अजादा है ऽ उससे रूप हाट की नयी र् नहीं । समय में अनहीं करने के लिए भी लहते हैं ऋ\" पृश् 100\n",
            "Seed string:   एँ हैं ऽ उन्हें भोग किये बिना मेरी मु\n",
            "Result string: एँ हैं ऽ उन्हें भोग किये बिना मेरी मुझे पूर्ण हैं ऽ पृश्र्द्यीऐऊश् ण्श्र्श्ट उस साधरि में पूर्ण घ् 100\n",
            "Seed string:   तÝ बिलस्यÝ रहै ऽ कहै रतनाकर सु\n",
            "Result string: तÝ बिलस्यÝ रहै ऽ कहै रतनाकर सुन हम कÝ पर्म र् मारे सÝं ऽ मन मेरे होती है । पर उस् 100\n",
            "Epoch 32/50\n",
            "100000/100000 [==============================] - 56s 557us/step - loss: 1.0632 - accuracy: 0.6738\n",
            "Epoch 33/50\n",
            "100000/100000 [==============================] - 57s 567us/step - loss: 1.0250 - accuracy: 0.6843\n",
            "Epoch 34/50\n",
            "100000/100000 [==============================] - 57s 567us/step - loss: 0.9893 - accuracy: 0.6965\n",
            "Epoch 35/50\n",
            "100000/100000 [==============================] - 57s 570us/step - loss: 0.9565 - accuracy: 0.7052\n",
            "Epoch 36/50\n",
            "100000/100000 [==============================] - 57s 568us/step - loss: 0.9209 - accuracy: 0.7170\n",
            "Epoch 37/50\n",
            "100000/100000 [==============================] - 57s 572us/step - loss: 0.8853 - accuracy: 0.7258\n",
            "Epoch 38/50\n",
            "100000/100000 [==============================] - 56s 563us/step - loss: 0.8631 - accuracy: 0.7331\n",
            "Epoch 39/50\n",
            "100000/100000 [==============================] - 56s 560us/step - loss: 0.8308 - accuracy: 0.7425\n",
            "Epoch 40/50\n",
            "100000/100000 [==============================] - 57s 567us/step - loss: 0.8002 - accuracy: 0.7524\n",
            "Epoch 41/50\n",
            "100000/100000 [==============================] - 57s 567us/step - loss: 0.8366 - accuracy: 0.7412\n",
            "\n",
            "Seed string:    र् खर्च की बात नहीं । सिद्धान्त की ब्\n",
            "Result string:  र् खर्च की बात नहीं । सिद्धान्त की भाँत और मददूला ऽ यह बहर की लखय अने में ऽ जस्म् 100\n",
            "Seed string:   झटपट उठी । मानो नींद से चÝंकी ह\n",
            "Result string: झटपट उठी । मानो नींद से चÝंकी है कि यदिरालैं अपनी स्पदेह्थ का समय एक ही नहीं तो घ् 100\n",
            "Seed string:   आयो चीर॥ भक्त कारण रूप नरहरि, \n",
            "Result string: आयो चीर॥ भक्त कारण रूप नरहरि, मिलै संग तील बिधि दीजिय जगत जग जाऊ। पाल पद प्र 100\n",
            "Seed string:    बिना करम का मानव, फिरैं डांवाडोल्\n",
            "Result string:  बिना करम का मानव, फिरैं डांवाडोलांगी॥ दो -भंग रख कर करूं करि लछि अन बहुत कर् 100\n",
            "Seed string:   यार् गया घडी रात गये घर लÝटता ऽ\n",
            "Result string: यार् गया घडी रात गये घर लÝटता ऽ हो है कि यह दंचर् ततार केवल एक हैं ऽ हो असंघर 100\n",
            "Epoch 42/50\n",
            "100000/100000 [==============================] - 57s 566us/step - loss: 0.7583 - accuracy: 0.7670\n",
            "Epoch 43/50\n",
            "100000/100000 [==============================] - 57s 565us/step - loss: 0.7173 - accuracy: 0.7794\n",
            "Epoch 44/50\n",
            "100000/100000 [==============================] - 56s 562us/step - loss: 0.6822 - accuracy: 0.7892\n",
            "Epoch 45/50\n",
            "100000/100000 [==============================] - 57s 567us/step - loss: 0.6619 - accuracy: 0.7962\n",
            "Epoch 46/50\n",
            "100000/100000 [==============================] - 57s 567us/step - loss: 0.6374 - accuracy: 0.8024\n",
            "Epoch 47/50\n",
            "100000/100000 [==============================] - 57s 568us/step - loss: 0.6199 - accuracy: 0.8069\n",
            "Epoch 48/50\n",
            "100000/100000 [==============================] - 57s 570us/step - loss: 0.5951 - accuracy: 0.8146\n",
            "Epoch 49/50\n",
            "100000/100000 [==============================] - 57s 569us/step - loss: 0.6487 - accuracy: 0.7967\n",
            "Epoch 50/50\n",
            "100000/100000 [==============================] - 57s 572us/step - loss: 0.5523 - accuracy: 0.8304\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc_PiFOxC6jI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}